{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Złożoność i wybór modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=tocheading>Spis treści</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef, confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_diabetes, load_linnerud, make_regression, make_s_curve\n",
    "from sklearn.datasets import make_friedman1, make_friedman2, make_friedman3, make_sparse_uncorrelated\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.cross_validation import cross_val_predict, KFold, StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astroML.datasets import fetch_imaging_sample\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from astroML.cosmology import Cosmology\n",
    "from astroML.datasets import generate_mu_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Błąd testujący i bład uczenia\n",
    "\n",
    "* __Generalizacja__ określa jak dobrze model będzie sobie radził na danych, których __nie__ widział w trakcie uczenia\n",
    "  * potrzebujemy metod, które\n",
    "    1. określać jakość modeli\n",
    "    * porównywać modele\n",
    "    * wybierać najlepszy model dla zadanego problemu\n",
    "      * to dotyczy zarówno typu modelu jak i wyboru parametrów\n",
    "    * oceniać końcowy błąd wybranego modelu\n",
    "    * oceniać złożoność modelu\n",
    "    \n",
    "    \n",
    "* __funkcja kosztu__ (__loss function__) jest miarą błędu jaki model popełnia, na przykład funkcja kwadratowa $$L(Y, \\hat{f}(X)) = (Y-\\hat{f}(X))^2$$\n",
    "* funkcja $\\hat{f}$ została nauczona na danych __trenujących__\n",
    "  * funkcja kwadratowa jest szeroko używana w zadaniu regresji, ale są dla niego także inne wybory\n",
    "  * dla klasyfikacji jest wiele innych opcji\n",
    "  \n",
    "  \n",
    "* błąd __testujący__ (albo __generalizacji__) to błąd predykcji (regresji) modelu (nauczonego na zbiorze $\\mathcal{T}$) na __ustalonej niależnej__ próbce danych $$Err_\\mathcal{T}=E[L(Y, \\hat{f}(X))|\\mathcal{T}]]$$\n",
    "* __oczekiwany błąd predykcji__ to $$Err=E[L(Y, \\hat{f}(X))]=E[Err_\\mathcal{T}]$$\n",
    "  * to wartość oczekiwana po wszelkich zbiorach uczących (a wobec tego po wszelkich $\\hat{f}$) i zbiorach testujących\n",
    "  * będziemy potrzebowali odpowiedniej procedury by estymować $Err$ i wybrać minimalizujący go model\n",
    "* błąd __uczenia__ to średni koszt dla zbioru czącego $$err=\\frac{1}{N}\\sum_i L(Y, \\hat{f}(X))$$\n",
    "  * błąd trenujący __nie jest__ dobrym przybliżeniem błędu predykcji!\n",
    "  \n",
    "  \n",
    "* podobnie dla innych rodzajów błędów\n",
    "  \n",
    "   \n",
    "\n",
    "* typowym problemem jest __brak danych__\n",
    "  * jesli danych jest bardzo dużo, to można rozdzielić dane na \n",
    "    1. __uczące__: dla nauczania\n",
    "    * __walidujące__: dla wyboru optymalnych parametrów\n",
    "    * __testujące__: dla sprawdzania błędu generalizacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział błędu na odchylenie i wariancję (bias-variance decomposition)\n",
    "\n",
    "* dane pochodzą z procesu pomiaru, są wobec tego obarczone __nieusuwalnym błędem__ $\\epsilon$ $$y_i=f(x_i)+\\epsilon$$\n",
    "  * prawdziwa (true) funkcja $f$ jest nieznana\n",
    "  * o błędzie można założyć, że $E[\\epsilon]=0$ oraz $E[\\epsilon^2]=\\sigma^2$\n",
    "  \n",
    "  \n",
    "* zakładamy, że $L()$ jest __kwadratowa__\n",
    "$$\\begin{align}\n",
    "Err(x)&=E[L(Y, \\hat{f}(X))|X=x]=E[(y-\\hat{f}(x))^2]\\\\\n",
    "&=E[(f(x)+\\epsilon-\\hat{f}(x))^2]=E[(f(x)-\\hat{f}(x)+\\epsilon)^2]\\\\\n",
    "&=E[(f(x)-\\hat{f}(x))^2]+E[2\\epsilon(f(x)-\\hat{f}(x))]+E[\\epsilon^2]&\\text{błąd $\\epsilon$ jest nieskorelowany z błędem predykcji}\\\\\n",
    "&=E[(f(x)-\\hat{f}(x))^2]+E[\\epsilon^2]\\\\\n",
    "\\\\\n",
    "&=E\\left[\\left(f(x)-E[\\hat{f}(x)]+E[\\hat{f}(x)]-\\hat{f}(x)\\right)^2\\right]+E\\left[\\epsilon^2\\right]\\\\\n",
    "\\\\\n",
    "&=E\\left[\\left(f(x)-E[\\hat{f}(x)]\\right)^2\\right]\\\\\n",
    "&+E\\left[\\left(f(x)-E[\\hat{f}(x)]\\right)\\left(E[\\hat{f}(x)]-\\hat{f}(x)\\right)\\right]&\\text{błedy są znowu nieskorelowane}\\\\\n",
    "&+E\\left[\\left(E[\\hat{f}(x)]-\\hat{f}(x)\\right)^2\\right]+E\\left[\\epsilon^2\\right]\\\\\n",
    "\\\\\n",
    "&=\\underbrace{E\\left[\\left(f(x)-E[\\hat{f}(x)]\\right)^2\\right]}_{\\text{bias}^2}\n",
    "+\\underbrace{E\\left[\\left(E[\\hat{f}(x)]-\\hat{f}(x)\\right)^2\\right]}_{\\text{wariancja modelu}}\n",
    "+\\underbrace{E\\left[\\epsilon^2\\right]}_{\\text{szum danych}}\n",
    "\\end{align}$$\n",
    "\n",
    "* __bias$^2$__: to suma kwadratów różnic między wartością prawdziwej (ale nieznanej) funkcji $f()$ a wartością oczekiwaną estymacji,\n",
    "* __wariancja modelu__: (czasem __błąd estymacji__) używając różnych zbiorów uczących, różnych parametrów modelu, różnych punktów startu (w algorytmach iteracyjnych) możemy dostać różne dofitowania modelu, a stąd modele będą miały pewną wariancję wokół wartości średniej\n",
    "* __szum danych__: jest niezależny od procesu uczenia; zwykle jest to biały szum\n",
    "\n",
    "\n",
    "\n",
    "* rozkład błędu pozwala na wyciągnięcie wniosków o uczeniu\n",
    "  * oczekujemy, że model bedzie __maksymalnie prosty__\n",
    "    * wtedy jednak możliwy jest wysoki bias, gdy model jest __prostszy__ od rzeczywistych danych (estymacja wielomiany prostą)\n",
    "    * bias można zredukować przez zwiększenie przestrzeni dostępnych funkcji\n",
    "    * modele w których bias przeważa często \"__underfitują__\"\n",
    "      * zwykle na początku uczenia model jest zwykle bardzo prosty, ma duzy błąd a bias przeważa nad wariancję\n",
    "      * proste modele: wysoki bias i niska wariancja\n",
    "  * jednocześnie chcemy, by model dobrze się __dostosowywał__\n",
    "    * wtedy może mieć wysoką wariancję\n",
    "      * podczas procesu uczenia  model coraz lepiej dostosowuje się, bias i błąd spadają\n",
    "      * błąd dla zbioru trenującego stale maleje\n",
    "      * jednak wariancja (dla różnych modeli) zaczyna wzrastać i nie ma pewności czy model bedzie dobrze generalizował\n",
    "      * modele z przewagą wariancji często \"__przefitowują__\"\n",
    "      * modele z ograniczoną przestrzenią funkcji (np. ridge, lasso) dają niską wariancję\n",
    "      * złożony model: niski bias i wysoka wariancja\n",
    "  * rozwiązania?\n",
    "    * uczenie należy przerwać wcześniej nim osiągnie minimalny błąd\n",
    "      * metoda wczesnego zatrzymywania (early stopping)\n",
    "      * kontrola za pomocą zbioru walidacyjnego\n",
    "      * metoda walidacji krzyżowej\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "* analogiczne rozumowanie dla innych funkcji kosztu nie jest oczywiste\n",
    "  * Domingos zaproponował ostatnio rozwinięcie do zero-jedynkowej funkcji kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bootstrap_linear_approximations(models=10, n_samples=100, noise=0.5):\n",
    "    X = np.random.uniform(-5, +5, [n_samples, 1])\n",
    "    #X = np.linspace(-5, 5, 100).reshape((100, 1))\n",
    "    t0 = 0.25; t1 = 0.02; t2 = 0.04; t3 = 0.04\n",
    "    y_true =  (0.25 + t1 * X + t2 * X**2 + t3 * X**3).reshape((n_samples,))\n",
    "    if noise > 0.:\n",
    "        y = y_true + np.random.normal(scale=noise, size=len(y_true))\n",
    "    else:\n",
    "        y = y_true\n",
    "    #print 'X.shape = {}, y_true.shape = {}, y.shape = {}'.format(X.shape, y_true.shape, y.shape)\n",
    "    #print X\n",
    "    #print y_true\n",
    "    #print y\n",
    "    y_noise = np.sum((y - y_true) ** 2) / n_samples\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    xmin, xmax = min(X), max(X)\n",
    "    ymin, ymax = min(y), max(y)\n",
    "    x_range = np.linspace(xmin, xmax, 100)\n",
    "    ax.plot(X, y, 'r*')\n",
    "    ax.plot(X, y_true, 'g*')\n",
    "    ax.grid()\n",
    "    #ax.plot(x_range, x_range * theta_data[1] + theta_data[0], 'k-')\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    \n",
    "    theta = np.zeros((models, 2))\n",
    "    predicted_all = np.zeros((models, len(y)))\n",
    "    #print np.mean(y)\n",
    "    print '\\tnoise\\t  variance\\t  bias\\t\\t  mse\\n{}'.format('-' * 70)\n",
    "    for k in range(models):\n",
    "        X_train, y_train = resample(X, y)\n",
    "        clr = LinearRegression()\n",
    "        clr.fit(X_train, y_train)\n",
    "        predicted = clr.predict(X)\n",
    "        predicted_all[k, :] = predicted\n",
    "        theta_fit = [np.mean(predicted), clr.coef_]\n",
    "        ax.plot(x_range, x_range * theta_fit[1] + theta_fit[0], lw=1)\n",
    "        theta[k, :] = theta_fit\n",
    "        y_fit_mean = np.mean(predicted)\n",
    "        var = np.sum((y - y_fit_mean) ** 2) / n_samples\n",
    "        bias_squared = np.sum((y_true - y_fit_mean) ** 2) / n_samples\n",
    "        mse = y_noise + var + bias_squared\n",
    "        err = np.sum((y - predicted) ** 2) / n_samples\n",
    "        #print '{}: \\t{}\\t+ {}\\t+ {}\\t= {}'.format(k, np.round(y_noise, 4), np.round(var, 4), \n",
    "        #                                             np.round(bias_squared, 4), np.round(mse, 4))\n",
    "        \n",
    "    theta_mean = np.mean(theta, 0)\n",
    "    ax.plot(x_range, x_range * theta_mean[1] + theta_mean[0], 'k-', lw=5)\n",
    "    # teraz licze oczekiwana wartosc obliczonej funkcji\n",
    "    y_ens_fit = np.mean(predicted_all, 0)\n",
    "    y_ens_fit_mean = np.mean(y_ens_fit)\n",
    "    var = 0\n",
    "    for m in range(models):\n",
    "        var = np.sum((y_ens_fit - predicted_all[m, ]) ** 2)\n",
    "    var /=  models * n_samples ** 2\n",
    "    # var = np.sum((y_ens_fit - y_ens_fit_mean) ** 2) / (n_samples ** 2)\n",
    "    bias_squared = np.sum((y_true - y_ens_fit) ** 2) / n_samples\n",
    "    mse = y_noise + var + bias_squared\n",
    "    err = np.sum((y_true - y_ens_fit) ** 2) / n_samples\n",
    "    print '{}: \\t{}\\t+ {}\\t+ {}\\t= {}'.format('ens', np.round(y_noise, 4), np.round(var, 4), \n",
    "                                                  np.round(bias_squared, 4), np.round(mse, 4))\n",
    "    \n",
    "    compute_ensembles = True\n",
    "    if compute_ensembles:\n",
    "        max_models = 100\n",
    "        for k in range(1, models):\n",
    "            comb = [c for c in combinations(range(models), k)]\n",
    "            # select max_models indices\n",
    "            ind = list(np.random.choice(len(comb), max(max_models, len(comb))))\n",
    "            var_ens = 0\n",
    "            bias_squared_ens = 0\n",
    "            mse_ens = 0\n",
    "            for q in ind:\n",
    "                p = comb[q]\n",
    "                y_ens_fit = np.mean(predicted_all[p, ], 0)\n",
    "                y_ens_fit_mean = np.mean(y_ens_fit)\n",
    "                var = 0\n",
    "                for m in p:\n",
    "                    var = np.sum((y_ens_fit - predicted_all[m, ]) ** 2)\n",
    "                var /=  len(p) * n_samples ** 2\n",
    "                var_ens += var / len(p)\n",
    "                bias_squared = np.sum((y_true - y_ens_fit) ** 2) / n_samples\n",
    "                bias_squared_ens += bias_squared / len(p)\n",
    "            var_ens /= len(ind)\n",
    "            bias_squared_ens /= len(ind)\n",
    "            mse = y_noise + var_ens + bias_squared_ens\n",
    "            print '{}:{}: \\t{}\\t+ {}\\t+ {}\\t= {}'.format('e', k, np.round(y_noise, 4), np.round(var_ens, 4), \n",
    "                                                              np.round(bias_squared_ens, 4), np.round(mse, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bootstrap_linear_approximations(models=10, n_samples=40, noise=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-wariancja dla modelu k-najbliższych sąsiadów\n",
    "$$\\begin{align}\n",
    "Err(x)&=\\underbrace{E\\left[\\left(f(x)-E[\\hat{f}(x)]\\right)^2\\right]}_{\\text{bias}^2}\n",
    "+\\underbrace{E\\left[\\left(E[\\hat{f}(x)]-\\hat{f}(x)\\right)^2\\right]}_{\\text{wariancja modelu}}\n",
    "+\\underbrace{E\\left[\\epsilon^2\\right]}_{\\text{szum danych}}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "* Dla k-najbliższych sąsiadów\n",
    "$$ \n",
    "Err(x_0)=\\underbrace{\\left[f(x_0)-\\frac{1}{k}\\sum_{p=1}^k{f}(x_{(p)})\\right]^2}_{\\text{bias}^2}\n",
    "+\\underbrace{\\frac{\\sigma_{\\epsilon}^2}{k}}_{\\text{wariancja modelu}}\n",
    "+\\underbrace{\\sigma^2}_{\\text{szum danych}}\n",
    "$$\n",
    "  * przykłady uczące $x$ są ustalone\n",
    "  * złożoność modelu jest w odwrotnej relacji do liczby sąsiadów _k_\n",
    "  * wraz ze wzrostem _k_ kwadrat różnicy między prawdziwą wartością $f(x_0)$ a średnią z najbliższych sąsiadów __rośnie__ (czyli rośnie bias) a wariancja maleje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"bias_variance_decomposition.png\" width=\"80%\"/> [rysunek: Hastie et al.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"bias_variance_tradeoff.png\" width=\"80%\" /> [rysunek: Hastie et al.]\n",
    "* bias (zielony), wariancja niebieski), całkowity błąd (pomarańczowy)\n",
    "* w problemach regresji (górny wiersz) bias i wariancja dodają się dając całkowity błąd\n",
    "* w problemach klasyfikacji\n",
    "  * bias i wariancja są takie same jak w problemach regresji\n",
    "  * błąd predykcji __nie jest__ już sumą wariancji i biasu\n",
    "    * niech prawdopodobieństwo danej klasy wynosi $0.85$ a wartość estymacji $0.55$\n",
    "    * wartość biasu $(0.85-0.55)^2$ ma jednak w dalszym ciągu dużą wartość\n",
    "    * predykcja jest jednak prawidłowa i błąd predykcji jest zerowy!\n",
    "* rozwiązania dla problemów regresji i predykcji są dramatycznie różne!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wybór (selection) i ocena (assessment) modelu\n",
    "* problem braku danych\n",
    "* podział danych\n",
    "* ocena modelu niemożliwa na danych uczących"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Walidacja krzyżowa\n",
    "\n",
    "* danych zwykle brakuje, w przeciwnym wypadku można łatwo podzielić na zbiory __uczący__, __walidujący__ i __testujący__\n",
    "* jak wykorzystać wszystkie dane do uczenia pozostawiając sobie dane do testowania???\n",
    "\n",
    "\n",
    "\n",
    "* __walidacja krzyżowa__\n",
    "  * podzielić zbiór danych na __K__ części\n",
    "    * zwykle K = 3, 5, 10\n",
    "    * podział powinien być losowy\n",
    "    * dla problemów klasyfikacji często wykorzystywana __stratyfikacja__\n",
    "  * powtórzyć K-krotnie \n",
    "    * nauczyć model na $K-1$ częściach\n",
    "    * ocenić rozwiązanie na pozostałej części\n",
    "  * końcowy błąd walidacji krzyżowej\n",
    "  $$\\boxed{CV(\\hat{f})=\\frac{1}{N}\\sum_{i=1}^NL(y_i, \\hat{f}^{-k(i)}(x_i))\\;}$$\n",
    "  gdzie $\\hat{f}^{-k(i)}(x_i))$ jest wartością dla tego modelu, w którym przykład $x_i$ __nie był__przykładem uczącym\n",
    "  * dla $K=N$ jest to metoda __leave_one_out__\n",
    "    * ta estymacja ma dużą wariancję ze względu na podobieństwo przykładów       \n",
    "    * kosztowne obliczeniowo\n",
    "  * dla niskiego K wariancja będzie niska\n",
    "    * problemem będzie wysoki bias modeli\n",
    "    * niskie K powoduje zwykle przecenianie błędu generalizacji\n",
    "    * wysokie K daje wysoką wariancję\n",
    "    \n",
    "    \n",
    "  * K=10 wydaje się dobrym rozwiązaniem\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Problemy z walidacją krzyżową\n",
    "* potrzebujemy zbudować najlepszy model dla zrównoważonego problemu klasyfikacji\n",
    "  \n",
    "  \n",
    "1. podejście pierwsze (za Hastie et al.)\n",
    "  1. dla całego zbioru wybieramy podzbiór zmiennych niezależnych o najwyższej korelacj z wyjściowymi etykietami\n",
    "  2. używając tych zmiennych budujemy klasyfikator\n",
    "  3, korzystając z walidacji krzyżowej określamy parametry i oceniamy model\n",
    "2. podejście drugie\n",
    "  1. podział danych na K foldów\n",
    "  2. dla każdych K-1 foldów wybieramy zmienne niezależne o najwyższej korelacji ze zmienną zależną dla tych K-1 foldów\n",
    "  3. budujemy klasyfikator z tych zmiennych dla przykładów z tych K-1 foldów\n",
    "  4. oceniamy predykcję na pozostałym K-tym foldzie\n",
    "  \n",
    "  \n",
    "* które podejścoie jest prawidłowe?\n",
    "* co jest niepoprawne w drugim podejściu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* K-ty fold musi być odłożony __przed__ jakimikolwiek operacjami w sposób __niezwiązany__ z etykietami\n",
    "* ten błąd jest popełniany bardzo często w artykułach naukowych\n",
    "  * autorzy często, czasem nieświadomie, dokonuje wstępnej selekcji cech i przykładów co wpływa na wyniki!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bootstrap\n",
    "* bootstrap to uogólnienie walidacji krzyżowej\n",
    "\n",
    "\n",
    "* procedura bootstrap\n",
    "  1. B-krotnie wylosować __z powtórzeniami__ próbkę uczącą $Z=\\{(x_i,y_i)\\}$\n",
    "    * zwykle B=100\n",
    "  2. model jest uczony ponownie dla zbioru Z\n",
    "  3. z tego można obliczyć estymację oczekiwanego błędu generalizacji\n",
    "  $$\\widehat{Err}=\\frac{1}{B}\\frac{1}{N}\\sum_{b=1}^B\\sum_{i=1}^NL(y_i, \\hat{f}^{*b}(x_i)),$$ gdzie $\\hat{f}^{*b}(x_i)$ jest wartością modelu dla b-tego zbioru bootstrap dla $x_i$\n",
    "  \n",
    "* taka procedura jest zbyt optymistyczna\n",
    "  * zbiory uczący i testujące przecinają się i predykcje nadmiernie dopasowują się (overfitting)\n",
    "  * jakie jest prawdopodobieństwo, że i-ta obserwacja będzie w b-tym zbiorze bootstrap? \n",
    "  $$\\begin{align}P(i; b)&=1-P(-i;b)=1-\\left(1-\\frac{1}{N}\\right)^N\\\\\n",
    "  &\\approx 1-e^{-1}\\approx0.632\\end{align}$$\n",
    "  * stąd wartość oczekiwana (dla binarnego problemu) $E[\\widehat{Err}]=0.5\\times(1-0.632)=0.184$\n",
    "    * to znacznie bardziej optymistyczna wartość niż oczekiwane $0.5$!\n",
    "  * bootstrap powinno działac tak, jak walidacja krzyżowa!\n",
    "    * z każdym przykładem zachowujemy listę indeksów $C^{-i}$ zbiorów bootstrap b w których przykład i-ty __nie__ występował\n",
    "    $$\\boxed{\n",
    "    \\widehat{Err}^{(1)}=\\frac{1}{N}\\sum_{i=1}^N\\frac{1}{|C^{-i}|}\\sum_{b\\in C^{-i}}L(y_i, \\hat{f}^{*b}(x_i))\n",
    "    \\;}$$\n",
    "      * B powinno być na tyle duże, by każdy przykład chociaż raz __nie__ występował w zbiorze uczącym\n",
    "  * liczba różnych przykładów w każdym zbiorze bootstrap jest rzędu $0.632N$\n",
    "    * stąd zbiór jest \"mały\" w stosunku do całego i może mieć duży bias\n",
    "    * będzie przypominać walidację krzyżową z dwoma foldami i pesymistycznym błędem\n",
    "    * poprawka statystyczna\n",
    "    $$\\boxed{\n",
    "    \\widehat{Err}^{(0.632)}=0.368\\times\\overline{err}+0.632\\times \\widehat{Err}^{(1)}\n",
    "    ,\\;}$$\n",
    "      * gdzie $\\overline{err}$ jest błędem na zbiorze trenującym\n",
    "      * działa czasem źle w sytuacjach nadmiernego dopasowania\n",
    "      * istnieją dodatkowe rozszerzenia bootstrap\n",
    "* bootstrap bywa kosztowne obliczeniowo ze względu na dużą liczbę modeli do znalezienia\n",
    "  * jednak estymacja oczekiwanej predykcji jest lepsza niż ta walidacji krzyżowej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A jak znaleźć najlepszy model?\n",
    "\n",
    "\n",
    "* mamy zbiór modeli z danej rodziny\n",
    "* dostępny jest także zestaw zbiorów uczących z pewnej rodziny, np. zastosowania\n",
    "* zmienne są architektura modeli, parametry i ich liczba\n",
    "* potrzebujemy określić jak algorytmy z tej rodziny radzą sobie z zadanymi problemami\n",
    "\n",
    "\n",
    "\n",
    "1. podziel zbiór uczący na K foldów\n",
    "2. for k=1,...,K\n",
    "  1. podziel K-1 foldów poza k-tym na P foldów\n",
    "  2. for p=1,...,P\n",
    "     1. naucz każdy z ustalonych modeli (architektury, układy parametrów, funkcje bazowe, etc.) na P-1 foldach poza p-tym\n",
    "     2. oceń każdy model na p-tym foldzie\n",
    "   3. wybierz najlepszy model (z najlepszą statystyką CV) (lub kilka)\n",
    "   4. oceń wybrany model n k-tym foldzie\n",
    "3. wylicz końcowe statystyki walidacji krzyżowej\n",
    "\n",
    "\n",
    "\n",
    "* procedura kosztowna i czasochlonna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocena jakości modelu\n",
    "\n",
    "* po uczeniu potrzebujemy określić jego __jakość__ na ile dobrze będzie on minimalizował popełniane błędy\n",
    "  * w trakcie uczenia minimalizowana jest __funkcja celu__ przyjęta na początku: kwadratowa, entropii krzyżowej, etc\n",
    "  * później jednak potrzebna jest inna (niekoniecznie jedyna) miara __dobroci__ modelu\n",
    "  * ta funkcja ocenia jak dobrze przybliżane są przykłady ze zbioru danych (czące czy testujące), niekoniecznie jest to bezpośrednia wartość funkicji celu\n",
    "  * __minimalizacja danej funkcji celu _niekoniecznie_ minimalizuje także inną funkcję jakości__\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje oceniające (score functions) dla problemów regresji\n",
    "* __średni błąd kwadratowy__ $$MSE(y, \\hat{y})=\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2$$\n",
    "  * MSE może przyjmować dowolne (dodatnie) wartości; jest bezpośrednio minimalizowana przez model używający kwadratowej funkcji kosztu\n",
    "  * tzw. __outliers__ mają duży wpływ na jej wartość\n",
    "  \n",
    "  \n",
    "  \n",
    "* __średni błąd bezwzględny__ $$MAE(y, \\hat{y})=\\frac{1}{N}\\sum_{i=1}^N|y_i-\\hat{y}_i|$$\n",
    "  * bezpośrednio minimalizowany przez sieci z funkcją kosztu $\\ell_1$\n",
    "    * rzadziej wykorzystywane ze względu na nieciągłość pochodnej $\\ell_1$\n",
    "      * zwykle obsługiwane programistycznie\n",
    "  * redukuje wpływ outliers  \n",
    "  \n",
    "  \n",
    "* __bezwzględny błąd mediany__ $$MedAE(y,\\hat{y})=median(\\{|y_i-\\hat{y}_i|\\}_{i=1}^N)$$\n",
    "  * szczególnie odporny na outliers\n",
    "   \n",
    "   \n",
    "* __miara $R^2$__ $$R^2(y,\\hat{y})=1-\\frac{\\sum_i(y_i-\\hat{y}_i)^2}{\\sum_i(y_i-\\overline{y})^2},$$\n",
    "gdzie $\\overline{y}_i$ jest __średnią__ prawdziwych wyjsciowych wartości\n",
    "  * $R^2$ odpowiada __współczynnikowi uwarunkowania__\n",
    "  * ocenia na ile dobrze przyszłe przykłady będą przybliżane\n",
    "  * model przybliżający idalnie ma wartość $R^2=1$\n",
    "  * model zwracający zawsze wartość oczekiwaną ma $R^2=0$\n",
    "    * ten model __nie zwraca__ uwagi na atrybuty wejściowe\n",
    "  * modele jeszcze słabsze mogą mieć wartości %R^2$ ujemne\n",
    "  * $R^2$ pozwala częściowo porównywać różne modele, także na różncy danych, co jest trudne dla regresji\n",
    "  \n",
    "  \n",
    "* __miara tłumacząca przez wariancję__ $$ev(y,\\hat{y})=1-\\frac{var\\{y-\\hat{y}\\}}{var\\{y\\}}$$\n",
    "  * najlepszy model ma wartość $1.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje oceniające dla problemów klasyfikacji\n",
    "* __accuracy__ $$acc(y,\\hat{y})=\\frac{1}{N}\\sum_i1(\\hat{y}_i=y_i)$$\n",
    "  * właściwie ułamek przykładów poprawnie zaklasyfikowanych, stąd $acc\\in[0,1]$\n",
    "  * odpowiada zero-jedynkowej funkcji kosztu\n",
    "  * podobnie __miara Hamminga__ zwraca frakcję źle przewidzianych etykiet\n",
    "  * __miara Jaccarda__ zwraca frakcję identycznie etykietowanych przez liczność etykiet\n",
    "  \n",
    "  \n",
    "* __macierz pomyłek (_confusion matrix_)__\n",
    "  * macierz $K\\times K$ opisująca błędne przypisania przykładów z prawdziwej klasy $i$ do innej (nieprawdziwej) klasy $j$\n",
    "  * macierz idealna jest przekątniowa\n",
    "  * elementy macierzy mgą być liczbą bądź frakcją przypisań\n",
    "  * pozwala na analizę działąnia algorytmu\n",
    "    * jeśli liczności klas są niezrównoważone, to bardziej ogólne miary ukrywają to, a macierz pomyłek pozwala znaleźć specyficzne zachowania\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "* __entropia krzyżowa__ $$H(y,\\hat{y})=-\\sum_iy_i\\ln(\\hat{y}_i)+(1-y_i)\\ln(1-\\hat{y}_i)$$\n",
    "  * zwane też __log loss__ (logarytm __naturalny__)\n",
    "  * dla $N$ przykładów i $K$ klas entropia krzyżowa bedzie miała postać $$H(y,\\hat{y})=-\\frac{1}{N}\\sum_i^N\\sum_k^Ky_{ik}log\\hat{y}_{ik}$$\n",
    "  * $\\hat{y}_i$ jest estymowanym prawdopodobieństwem, że $y_i=1$\n",
    "  * bezpośrednio minimalizowalna funkcja kosztu\n",
    "  <img src=\"entropy000.png\" size=\"30%\"/>  <img src=\"entropy001.png\"/> [Rys. ze scikit-learn.org]\n",
    "  \n",
    "  \n",
    "  \n",
    "* __hinge loss__ $$L_{hinge}(y,\\hat{y})=\\max\\{1-y\\hat{y}, 0\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pojęcia false positives, false negatives i pochodne\n",
    "* w wielu problemach klasyfikacji (szczególnie binarnej) __błędy__ mogą być różnych typów:\n",
    "  * __FALSE POSITIVE__ polegające na wykryciu danej cechy, gdy w rzeczysitości ta tam jej __nie ma__\n",
    "  * __FALSE NEGATIVE__ polegające na __nie wykryciu__ cechy, gdy ona jest\n",
    "  * uzupełniające stany to __TRUE POSITIVE__ i __TRUE NEGATIVE__\n",
    "  * niektóre błędy są w oczywisty sposób bardziej kosztowne\n",
    "  * jeśli dana cecha występuje __bardzo rzadko__, to prosty klasyfikator __nigdy__ jej nie wykryje __wciąż osiągająć wysoką dokładność__ (accuracy)!\n",
    "  \n",
    "  \n",
    "  \n",
    "* __accuracy__ $$ACC=\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "* __specificity__ $$specificity=\\frac{TN}{TN+FP}$$\n",
    "  * frakcja poprawnego wykrycia braku cechy tam gdzie jej nie ma\n",
    "  * $1-specificity = \\frac{FP}{FP+TN}$ to __false positive rate FPR__ czyli frakcja niepoprawnego wykrycia cechy wśród przypadków gdzie jej nie ma \n",
    "* __sensitivity (recall)__ $$sensitivity=\\frac{TP}{TP+FN}$$\n",
    "  * frakcja poprawnego wykrycia cechy tam gdzie ona jest\n",
    "  * $1-sensitivity=\\frac{FN}{TP+FN}$ to __false negative rate FNR__ czyli frakcja niepoprawnego niewykrycia cechy wśród przypadków, gdzie ona jest\n",
    "  \n",
    "  \n",
    "* __Receiver Operating Characteristic ROC__ to __stosunek TPR (sensitivity, czułość) do FPR = 1 - specificity)__\n",
    "  * najlepszy możliwy wybór jest w lewym górnym rogu\n",
    "    * TPR=1.0 czyli poprawne wykrycie cechy zawsze gdy jest\n",
    "    * FPR=0.0 czyli nigdy nie zaznaczenie cechy jeśli jej nie ma\n",
    "  * klasyfikotorom wykorzytującym losowy wybór odpowiada przekątna\n",
    "    * poniżej przekątnej są lasyfikatory __gorsze__ od losowych\n",
    "  * __krzywe ROC__ dla zadanego klasyfikatora binarnego\n",
    "    * niech $t$ będzie progiem i $x$ jest zaliczany do klasy $C_1$ jeśli $\\hat{y}(x)>t$\n",
    "    * punkty $(FPR(t), TPR(t)$ wyznaczają krzywe\n",
    "    * znając wzajemne prawdopodobieństwo klas można znaleźć optymalny próg $t$ jako odpowiadający punktowi najbliższemu rogowi $(0, 1)$ na styku prostej odpowiadającej prawdopodobieństwu względnemu klas i krzywej ROC\n",
    "    \n",
    "    \n",
    "* __Area Under the Curve AUC__ pole pod powierzchnią krzywej ROC\n",
    "  * klasyfikator o większym AUC powinien mieć lepsze wyniki\n",
    "  * AUC odpowiada __prawdopodobieństwu__ że dla dwóch losowych przykładów, __pozytwnego__ i __negatywnego__, algorytm zaklasyfikuje wyżej ten pozytywny (jego uzna za bardziej prawdopodobny _pozytywny_)\n",
    "  * jednak obliczanie AUC wprowadza szum, więc nie jest calkiem wiarygodne i oparcie się na nim może prowadzić do błędów\n",
    "  * rozszerzenie do problemów wielo klasowych jest złożone\n",
    "  \n",
    "  \n",
    "  \n",
    "* wielu autorów używa ROC jako wykresu sensitivity do specificity\n",
    "  * optymalny klasyfikator mieści się w prawym górnym rogu..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_analysis(n_folds=11):\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    X, y = X[y != 2], y[y != 2]\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Add noisy features\n",
    "    random_state = np.random.RandomState(0)\n",
    "    X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "    # Classification and ROC analysis\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(y, n_folds=n_folds)\n",
    "    classifier = svm.SVC(kernel='linear', probability=True,\n",
    "                     random_state=random_state)\n",
    "\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 15))\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, lw=1, label='ROC fold %d (powierzchnia = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Losowy')\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    ax.plot(mean_fpr, mean_tpr, 'k--',\n",
    "             label='Mean ROC (powierzchnia = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate (1 - specificity)')\n",
    "    ax.set_ylabel('True Positive Rate (sensitivity)')\n",
    "    ax.set_title('ROC dla przykladu Iris z walidacja krzyzowa')\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'kernel' has incorrect type (expected str, got unicode)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6b7c13ed3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-da395c930aba>\u001b[0m in \u001b[0;36mroc_analysis\u001b[0;34m(n_folds)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Compute ROC curve and area the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/igorpodolak/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/igorpodolak/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'kernel' has incorrect type (expected str, got unicode)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBYAAANnCAYAAACF+9tAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115b4c810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score\n",
    "* __recall (sensitivity)__ $$recall=\\frac{TP}{TP+FN}$$\n",
    "  * ułamek wybranych należących do klasy (TP) i wybranych w stosunku do wszystkich z tej klasy (TP+FN)\n",
    "  * klasyfikator wybiera $TP+FP$ elementów, ale spośród nich tylko $TP$ poprawnie\n",
    "  * wybierając __wszystkie__ elementu maksymalizuje _recall_, ale ma niską precyzję\n",
    "* __precision__ $$precision=\\frac{TP}{TP+FP}$$\n",
    "  * ułamek poprawnie wybranych (TP) do wszystkich wybranych (TP+FP)\n",
    "  * wybierając tylko jeden element, chociaż poprawnie, klasyfikator osiąga wysoką precyzję, jednak wciąż niski recall\n",
    "  \n",
    "  \n",
    "* __miara F__ łączy $$F=2\\frac{precision\\cdot recall}{precision+ recall}$$\n",
    "  * równoważy precision i recall, inaczej __F1__\n",
    "  * ogólniej $$F_\\beta=(1+\\beta^2)\\frac{precision\\cdot recall}{\\beta^2\\cdot precision+recall}$$\n",
    "  \n",
    "  * dla problemów wieloklasowych\n",
    "    * miara F może być zastosowana do każdej z klas z osobna\n",
    "    * jest też kilka metod uśredniania miedzy klasami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matthews corellation ceofficient\n",
    "* $$MCC=\\frac{TP\\cdot TN-FP\\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n",
    "  * $MCC\\in[-1, 1]$\n",
    "  * MCC to współczynnik korelacji między prawdziwymi i przewidzianymi klasyfikacjami\n",
    "  * jest dobrą metodą przedstawienia macierzy pomyłek true/false positives/negatives w postaci jednej liczby\n",
    "  * często stosowana przez biologów (ale ograniczona do problemów binarnych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* teoria rozwinięta podczas pracy nad radarami w trakcie 2 wojny światowej\n",
    "  * analiza wykrywalności obcych samolotów na ekranach radarów; szczególnie po Pearl Harbour\n",
    "  * __false negative__ nie wykrycie japońskiego Zero na ekranie radaru\n",
    "  * __false positive__ fałszywy alarm wykrycia, często wynik szumu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
